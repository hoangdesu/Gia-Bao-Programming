{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForest\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Face Landmarker\n",
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "# Initialize MediaPipe drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Define function to compute Euclidean distance in 3D\n",
    "def distance_3d(p1, p2):\n",
    "    return np.sqrt(np.sum((np.array(p1) - np.array(p2)) ** 2))\n",
    "\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    face_landmarks_list = detection_result.face_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    for idx in range(len(face_landmarks_list)):\n",
    "        face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "        # Create landmark proto\n",
    "        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        face_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "        ])\n",
    "\n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "    return annotated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(coords):\n",
    "    # Define indices for landmarks\n",
    "    landmark_indices = {\n",
    "        'forehead': 10,\n",
    "        'chin': 152,\n",
    "        'left_cheek': 234,\n",
    "        'right_cheek': 454,\n",
    "        'left_eye': 263,\n",
    "        'right_eye': 33,\n",
    "        'nose_tip': 1\n",
    "    }\n",
    "\n",
    "    # Extract features based on landmark indices\n",
    "    features = []\n",
    "    landmarks_dict = {name: coords[idx] for name, idx in landmark_indices.items()}\n",
    "\n",
    "    # Calculate distances between important landmarks\n",
    "    features.append(distance_3d(landmarks_dict['forehead'], landmarks_dict['chin']))  # Face height\n",
    "    features.append(distance_3d(landmarks_dict['left_cheek'], landmarks_dict['right_cheek']))  # Face width\n",
    "    features.append(distance_3d(landmarks_dict['left_eye'], landmarks_dict['right_eye']))  # Eye distance\n",
    "\n",
    "    # Additional distances\n",
    "    features.append(distance_3d(landmarks_dict['nose_tip'], landmarks_dict['left_eye']))  # Nose to left eye\n",
    "    features.append(distance_3d(landmarks_dict['nose_tip'], landmarks_dict['right_eye']))  # Nose to right eye\n",
    "    features.append(distance_3d(landmarks_dict['chin'], landmarks_dict['left_cheek']))  # Chin to left cheek\n",
    "    features.append(distance_3d(landmarks_dict['chin'], landmarks_dict['right_cheek']))  # Chin to right cheek\n",
    "    features.append(distance_3d(landmarks_dict['forehead'], landmarks_dict['left_eye']))  # Forehead to left eye\n",
    "    features.append(distance_3d(landmarks_dict['forehead'], landmarks_dict['right_eye']))  # Forehead to right eye\n",
    "\n",
    "    # # Additional features\n",
    "\n",
    "    # # Facial aspect ratios\n",
    "    # face_width = distance_3d(landmarks_dict['left_cheek'], landmarks_dict['right_cheek'])\n",
    "    # face_height = distance_3d(landmarks_dict['forehead'], landmarks_dict['chin'])\n",
    "    # eye_distance = distance_3d(landmarks_dict['left_eye'], landmarks_dict['right_eye'])\n",
    "\n",
    "    # features.append(face_width / face_height)  # Aspect ratio of face width to height\n",
    "    # features.append(face_height / eye_distance)  # Aspect ratio of face height to eye distance\n",
    "\n",
    "    # # More distance features\n",
    "    # features.append(distance_3d(landmarks_dict['left_eye'], landmarks_dict['chin']))  # Eye to chin\n",
    "    # features.append(distance_3d(landmarks_dict['right_eye'], landmarks_dict['chin']))  # Eye to chin\n",
    "    # features.append(distance_3d(landmarks_dict['left_cheek'], landmarks_dict['forehead']))  # Cheek to forehead\n",
    "    # features.append(distance_3d(landmarks_dict['right_cheek'], landmarks_dict['forehead']))  # Cheek to forehead\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(folder_path):\n",
    "    faces = []\n",
    "    labels = []\n",
    "    \n",
    "    # Process each image in the dataset\n",
    "    for shape in os.listdir(folder_path):\n",
    "        print(f\"Processing face shape category: {shape}\")\n",
    "        k = shape\n",
    "        shape_pth = os.path.join(folder_path, shape)\n",
    "\n",
    "        for img in os.listdir(shape_pth):\n",
    "            img_pth = os.path.join(shape_pth, img)\n",
    "\n",
    "            # Load the image\n",
    "            pic = cv2.imread(img_pth)\n",
    "\n",
    "            if pic is None:\n",
    "                print(f\"Error loading image {img_pth}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Convert the image to RGB as required by MediaPipe\n",
    "            rgb_image = cv2.cvtColor(pic, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Create a MediaPipe Image object\n",
    "            image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)\n",
    "\n",
    "            # Detect face landmarks\n",
    "            detection_result = detector.detect(image)\n",
    "\n",
    "            if not detection_result.face_landmarks:\n",
    "                print(f\"No face landmarks detected for image {img_pth}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Extract the face landmarks\n",
    "            face_landmarks = detection_result.face_landmarks[0]\n",
    "            coords = [[landmark.x, landmark.y, landmark.z] for landmark in face_landmarks]\n",
    "            coords = np.array(coords)  # Convert to numpy array\n",
    "\n",
    "            # Extract features\n",
    "            features = extract_features(coords)\n",
    "\n",
    "            # Assign labels based on the face shape directory\n",
    "            if k == \"heart\":\n",
    "                labels.append(0)\n",
    "            elif k == \"oval\":\n",
    "                labels.append(1)\n",
    "            elif k == \"round\":\n",
    "                labels.append(2)\n",
    "            elif k == \"square\":\n",
    "                labels.append(3)\n",
    "            else:\n",
    "                print('ERROR')\n",
    "                break\n",
    "\n",
    "            faces.append(features)\n",
    "    \n",
    "    return np.array(faces), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for training and testing data\n",
    "train_data_pth = \"Face_Shape/training2\"\n",
    "test_data_pth = \"Face_Shape/testing2\"\n",
    "\n",
    "# Process the datasets\n",
    "X_train, y_train = process_data(train_data_pth)\n",
    "X_test, y_test = process_data(test_data_pth)\n",
    "\n",
    "# Print dataset shape\n",
    "print(f\"Training dataset shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing dataset shape: {X_test.shape}, Testing labels shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# Train the RandomForest model\n",
    "rf_model = RandomForestClassifier(n_estimators=1500, random_state=20)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained RandomForest model\n",
    "with open('Best_RandomForest.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
